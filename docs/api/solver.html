
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Linear Solvers &#8212; matx  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Matrix Inverse" href="inverse.html" />
    <link rel="prev" title="Matrix Multiply (GEMM)" href="matmul.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">matx  documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../build.html">
   Building MatX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../quickstart.html">
   Quick Start
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../creation.html">
   Creating Tensors
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="class.html">
     Tensor Class Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="tensorview.html">
       tensor_t
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tensorshape.html">
       tensorShape_t
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="transformations.html">
     Tensor Transformations
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="fft.html">
       FFT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="matmul.html">
       Matrix Multiply (GEMM)
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Linear Solvers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="inverse.html">
       Matrix Inverse
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="filter.html">
       Filtering (IIR and FIR)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="reduce.html">
       Reductions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sort.html">
       Sorting
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tensorops.html">
     Tensor Operators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tensorgenerators.html">
     Generator Operators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="stats.html">
     Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random.html">
     Random Number Generation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="utilities.html">
     Utilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="type_traits.html">
     Type Traits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="einsum.html">
     einsum
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../matlabpython.html">
   MATLAB/Python To MatX Translation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples/index.html">
   Example Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/fftconv.html">
     FFT Convolution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../limitations.html">
   Limitations
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/api/solver.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section id="linear-solvers">
<h1>Linear Solvers<a class="headerlink" href="#linear-solvers" title="Permalink to this headline"></a></h1>
<p>The linear solver interface provides methods for users to run a linear solver using either cuBLAS or
cuSolver as the backend.</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00EN4matx4cholEvR12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t">
<span id="_CPPv3I00EN4matx4cholER12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t"></span><span id="_CPPv2I00EN4matx4cholER12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">OutputTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ATensor</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="namespacematx_1aebb9b71229d37a348d1b6a712961a591"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">matx</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">chol</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4I00EN4matx4cholEvR12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t" title="matx::chol::OutputTensor"><span class="n"><span class="pre">OutputTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">out</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I00EN4matx4cholEvR12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t" title="matx::chol::ATensor"><span class="n"><span class="pre">ATensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">a</span></span>, <span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span>, <span class="n"><span class="pre">cublasFillMode_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">uplo</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">CUBLAS_FILL_MODE_UPPER</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I00EN4matx4cholEvR12OutputTensorRK7ATensor12cudaStream_t16cublasFillMode_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform a Cholesky decomposition using a cached plan</p>
<p>See documentation of matxDnCholSolverPlan_t for a description of how the algorithm works. This function provides a simple interface to the cuSolver library by deducing all parameters needed to perform a Cholesky decomposition from only the matrix A. The input and output parameters may be the same tensor. In that case, the input is destroyed and the output is stored in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T1</strong> – Data type of matrix A </p></li>
<li><p><strong>RANK</strong> – Rank of matrix A</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>out</strong> – Output tensor </p></li>
<li><p><strong>a</strong> – Input tensor </p></li>
<li><p><strong>stream</strong> – CUDA stream </p></li>
<li><p><strong>uplo</strong> – Part of matrix to fill </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN4matx2luEvR12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t">
<span id="_CPPv3I000EN4matx2luER12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t"></span><span id="_CPPv2I000EN4matx2luER12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">OutputTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">PivotTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ATensor</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="namespacematx_1a596cd5fea0e992f6d3b0cb86754776f3"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">matx</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">lu</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4I000EN4matx2luEvR12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t" title="matx::lu::OutputTensor"><span class="n"><span class="pre">OutputTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">out</span></span>, <a class="reference internal" href="#_CPPv4I000EN4matx2luEvR12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t" title="matx::lu::PivotTensor"><span class="n"><span class="pre">PivotTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">piv</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I000EN4matx2luEvR12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t" title="matx::lu::ATensor"><span class="n"><span class="pre">ATensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">a</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN4matx2luEvR12OutputTensorR11PivotTensorRK7ATensorK12cudaStream_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform a LU decomposition using a cached plan</p>
<p>See documentation of matxDnLUSolverPlan_t for a description of how the algorithm works. This function provides a simple interface to the cuSolver library by deducing all parameters needed to perform an LU decomposition from only the matrix A. The input and output parameters may be the same tensor. In that case, the input is destroyed and the output is stored in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T1</strong> – Data type of matrix A </p></li>
<li><p><strong>RANK</strong> – Rank of matrix A</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>out</strong> – Output tensor view </p></li>
<li><p><strong>piv</strong> – Output of pivot indices </p></li>
<li><p><strong>a</strong> – Input matrix A </p></li>
<li><p><strong>stream</strong> – CUDA stream </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN4matx2qrEvR9OutTensorR9TauTensorRK7ATensor12cudaStream_t">
<span id="_CPPv3I000EN4matx2qrER9OutTensorR9TauTensorRK7ATensor12cudaStream_t"></span><span id="_CPPv2I000EN4matx2qrER9OutTensorR9TauTensorRK7ATensor12cudaStream_t"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">OutTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">TauTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ATensor</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="namespacematx_1ab4995f533dba0349289592dcd507b960"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">matx</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">qr</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4I000EN4matx2qrEvR9OutTensorR9TauTensorRK7ATensor12cudaStream_t" title="matx::qr::OutTensor"><span class="n"><span class="pre">OutTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">out</span></span>, <a class="reference internal" href="#_CPPv4I000EN4matx2qrEvR9OutTensorR9TauTensorRK7ATensor12cudaStream_t" title="matx::qr::TauTensor"><span class="n"><span class="pre">TauTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">tau</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I000EN4matx2qrEvR9OutTensorR9TauTensorRK7ATensor12cudaStream_t" title="matx::qr::ATensor"><span class="n"><span class="pre">ATensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">a</span></span>, <span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN4matx2qrEvR9OutTensorR9TauTensorRK7ATensor12cudaStream_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform a QR decomposition using a cached plan</p>
<p>See documentation of matxDnQRSolverPlan_t for a description of how the algorithm works. This function provides a simple interface to the cuSolver library by deducing all parameters needed to perform a QR decomposition from only the matrix A. The input and output parameters may be the same tensor. In that case, the input is destroyed and the output is stored in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T1</strong> – Data type of matrix A </p></li>
<li><p><strong>RANK</strong> – Rank of matrix A</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>out</strong> – Output tensor view </p></li>
<li><p><strong>tau</strong> – Output of reflection scalar values </p></li>
<li><p><strong>a</strong> – Input tensor A </p></li>
<li><p><strong>stream</strong> – CUDA stream </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc">
<span id="_CPPv3I0000EN4matx3svdER7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc"></span><span id="_CPPv2I0000EN4matx3svdER7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">UTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">STensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">VTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ATensor</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="namespacematx_1a34b34776863370d0b29dbb632306eb1e"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">matx</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">svd</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc" title="matx::svd::UTensor"><span class="n"><span class="pre">UTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">u</span></span>, <a class="reference internal" href="#_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc" title="matx::svd::STensor"><span class="n"><span class="pre">STensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">s</span></span>, <a class="reference internal" href="#_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc" title="matx::svd::VTensor"><span class="n"><span class="pre">VTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">v</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc" title="matx::svd::ATensor"><span class="n"><span class="pre">ATensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">a</span></span>, <span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">char</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">jobu</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="sc"><span class="pre">'A'</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">char</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">jobvt</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="sc"><span class="pre">'A'</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN4matx3svdEvR7UTensorR7STensorR7VTensorRK7ATensor12cudaStream_tKcKc" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform a SVD decomposition using a cached plan</p>
<p>See documentation of matxDnSVDSolverPlan_t for a description of how the algorithm works. This function provides a simple interface to the cuSolver library by deducing all parameters needed to perform a SVD decomposition from only the matrix A.</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T1</strong> – Data type of matrix A </p></li>
<li><p><strong>RANK</strong> – Rank of matrix A</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>u</strong> – U matrix output </p></li>
<li><p><strong>s</strong> – Sigma matrix output </p></li>
<li><p><strong>v</strong> – V matrix output </p></li>
<li><p><strong>a</strong> – Input matrix A </p></li>
<li><p><strong>stream</strong> – CUDA stream </p></li>
<li><p><strong>jobu</strong> – Specifies options for computing all or part of the matrix U: = ‘A’. See cuSolver documentation for more info </p></li>
<li><p><strong>jobvt</strong> – specifies options for computing all or part of the matrix V**T. See cuSolver documentation for more info </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN4matx3eigEvR12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t">
<span id="_CPPv3I000EN4matx3eigER12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t"></span><span id="_CPPv2I000EN4matx3eigER12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">OutputTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">WTensor</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ATensor</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="namespacematx_1a62e9817e2c3e2e2e388ccb2b30754f76"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">matx</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">eig</span></span></span><span class="sig-paren">(</span><span class="pre">[[maybe_unused]]</span><span class="w"> </span><a class="reference internal" href="#_CPPv4I000EN4matx3eigEvR12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t" title="matx::eig::OutputTensor"><span class="n"><span class="pre">OutputTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">out</span></span>, <a class="reference internal" href="#_CPPv4I000EN4matx3eigEvR12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t" title="matx::eig::WTensor"><span class="n"><span class="pre">WTensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">w</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I000EN4matx3eigEvR12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t" title="matx::eig::ATensor"><span class="n"><span class="pre">ATensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">a</span></span>, <span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span>, <span class="n"><span class="pre">cusolverEigMode_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">jobz</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">CUSOLVER_EIG_MODE_VECTOR</span></span>, <span class="n"><span class="pre">cublasFillMode_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">uplo</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">CUBLAS_FILL_MODE_UPPER</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN4matx3eigEvR12OutputTensorR7WTensorRK7ATensor12cudaStream_t17cusolverEigMode_t16cublasFillMode_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform a Eig decomposition using a cached plan</p>
<p>See documentation of matxDnEigSolverPlan_t for a description of how the algorithm works. This function provides a simple interface to the cuSolver library by deducing all parameters needed to perform a eigen decomposition from only the matrix A. The input and output parameters may be the same tensor. In that case, the input is destroyed and the output is stored in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T1</strong> – Data type of matrix A </p></li>
<li><p><strong>RANK</strong> – Rank of matrix A</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>out</strong> – Output tensor view </p></li>
<li><p><strong>w</strong> – Eigenvalues output </p></li>
<li><p><strong>a</strong> – Input matrix A </p></li>
<li><p><strong>stream</strong> – CUDA stream </p></li>
<li><p><strong>jobz</strong> – CUSOLVER_EIG_MODE_VECTOR to compute eigenvectors or CUSOLVER_EIG_MODE_NOVECTOR to not compute </p></li>
<li><p><strong>uplo</strong> – Where to store data in A </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>


              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="matmul.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Matrix Multiply (GEMM)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="inverse.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Matrix Inverse</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Nvidia<br/>
        
            &copy; Copyright 2021, Nvidia.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
 

  <style>
         .wy-nav-content { max-width: 1600px; }
         .wy-table-responsive table td, .wy-table-responsive table th {
            white-space: normal;
          }          
  </style>


  </body>
</html>