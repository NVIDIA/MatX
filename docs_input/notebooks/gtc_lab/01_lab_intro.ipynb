{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// WARNING: DO NOT MODIFY, Requirements for C++ in notebook\n",
    "#pragma cling add_library_path(\"/usr/local/cuda/lib64\")\n",
    "#pragma cling add_library_path(\"/opt/xeus/cling/lib\")\n",
    "//#pragma cling add_library_path(\"/usr/Lib/gcc/x86_64-Linux-gnu/11/\")\n",
    "#pragma cling add_library_path(\"/usr/lib/x86_64-linux-gnu/openblas64-openmp/\")\n",
    "#pragma cling add_include_path(\"/usr/local/cuda/include\")\n",
    "#pragma cling add_include_path(\"/usr/include/x86_64-linux-gnu/openblas64-openmp\")\n",
    "#pragma cling add_include_path(\"/opt/xeus/cling/tools/Jupyter/kernel/MatX/include\")\n",
    "#pragma cling add_include_path(\"/opt/xeus/cling/tools/Jupyter/kernel/MatX/build/_deps/cccl-src/libcudacxx/include\")\n",
    "//#pragma cling load(\"libgomp\")\n",
    "#pragma cling load(\"libopenblas64\")\n",
    "#pragma cling load(\"libcuda\")\n",
    "#pragma cling load(\"libcudart\")\n",
    "#pragma cling load(\"libcurand\")\n",
    "#pragma cling load(\"libcublas\")\n",
    "#pragma cling load(\"libcublasLt\")\n",
    "\n",
    "#include <cuda/std/__algorithm/max.h>\n",
    "#include <cuda/std/__algorithm/min.h>\n",
    "\n",
    "#define MATX_EN_OPENBLAS\n",
    "#define MATX_EN_OPENBLAS_LAPACK\n",
    "#define MATX_OPENBLAS_64BITINT\n",
    "\n",
    "#include \"matx.h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// WARNGING: DO NOT execute this cell twice! If you do, restart the kernel and run all cells ONCE from the begining.\n",
    "auto exec = matx::SingleThreadedHostExecutor{};\n",
    "//auto exec = matx::cudaExecutor{};\n",
    "// WARNGING: DO NOT execute this cell twice! If you do, restart the kernel and run all cells ONCE from the begining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatX Introduction\n",
    "\n",
    "\n",
    "# MatX Integrated Demo Notebook\n",
    "## Notes on Operation\n",
    "This demo requires a very specific environment to enable C++17 native compilation in the Jupyter notebook cells, and comes with many caveats versus normal Jupyter notebooks. While state is preserverd across cells, the state of previously executed cells is persistent, unless it directly overwrites the \n",
    "\n",
    "\n",
    "### Container Startup \n",
    "Start container with all normal options, adding `-p 8888:8888`\n",
    "\n",
    "a sample `run.sh` script is provided in `MatX/docs_input/notebooks`\n",
    "\n",
    "### start Juptyer server locally in container\n",
    "`jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root` \n",
    "\n",
    "copy the token from the server start (specifically the local token should be something similar to:\n",
    "`http://127.0.0.1:8888/tree?token=a3ad60a152dcafe98d4eaecc22bd773b38f1e6e93312adae`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Creation and Memory Backing\n",
    "\n",
    "Tensors are the base class of memory backed data storage in MatX. The Tensor class is highly flexible with many options for memory backing, residency, and ownership, but has defaults that makes it easy to use out-of-the box. A set of utility `make_tensor` functions are provided out of the box to help streamline and simplify tensor creation; this is the suggested use pattern for beginners and experts alike. \n",
    "\n",
    "`make_tensor` takes one template parameter indicating the type of the tensor, and zero or more function parameters. At a minimum, the sizes of the tensor are specified in curly braces, or in the case of a 0-D tensor, no size list is specified. For a complete guide on creating tensors in different ways, please visit: https://nvidia.github.io/MatX/basics/creation.html.\n",
    "\n",
    "**NOTE** Unlike MATLAB, MatX follows the C-style for indexing, meaning we assume row-major formats rather than column-major, and 0-based indexing rather than 1-based. \n",
    "\n",
    "In the following cell we demonstrate creating tensors of 0D (scalar), 1D, and 2D data. Tensors can be scaled to any arbitrary dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 0D tensor (Scalar)\n",
    "  auto t0 = matx::make_tensor<int>({});\n",
    "\n",
    "  // declare a 1D tensor of length 4\n",
    "  auto t1 = matx::make_tensor<int>({4});\n",
    "\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // declare tensor with user provided memory (maybe?)\n",
    "\n",
    "  // declare tensor with shape of tensor t2\n",
    "  auto t2_b = matx::make_tensor<int>(t2.Shape());\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing & Assigning\n",
    "MatX also provides several utilities for initializing and viewing its data.\n",
    "\n",
    "Values can be initialized using a nested initializer list inside of the `SetVals` member function, specifying the values of the matrix. The initializer list is a single-nested list to match a 2D tensor shape, but this can be extended up to 4D tensors. `operator()` is also available to set and get individual values of a tensor as an alternative.\n",
    "\n",
    "`print` is a utility function to print a tensor or operator's contents to stdout. Printing can be used with any type of operator, including ones that have no memory backing them (see upcoming generators section). With no arguments `print` will print the entire contents of the tensor. The size of the printing can also be limited by passing a limit to each dimension. For example, `print(3,2)` would print the first 2 columns and 3 rows of the 2D tensor. `operator()` can also be used to retun a single value, and combine with traditional pritining techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // setVals in tensor\n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });\n",
    "\n",
    "  // print a tensor\n",
    "  matx::print(t2);\n",
    "\n",
    "  // print elements of tensor\n",
    "  std::cout << t2(0,0) << std::endl;\n",
    "\n",
    "  t2(0,0) = 42;\n",
    "  t2(3,2) = 117;\n",
    "\n",
    "  matx::print(t2);\n",
    "\n",
    "  std::cout << \"My updates value for (3,2): \" << t2(3,2) << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Creation Operators\n",
    "\n",
    "MatX also has a number of pre-built creation routines. For the full list, see https://nvidia.github.io/MatX/api/creation/operators/index.html.\n",
    "\n",
    "Shown below are [linspace](https://nvidia.github.io/MatX/api/creation/operators/linspace.html), [range](https://nvidia.github.io/MatX/api/creation/operators/range.html), and [ones](https://nvidia.github.io/MatX/api/creation/operators/ones.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  std::cout << \"Linspace (steps=10, start=0, stop=1)\" << std::endl;\n",
    "  auto tlin = matx::make_tensor<float>({10});\n",
    "  matx::print(tlin = matx::linspace<0>(tlin.Shape(), 0.0f, 1.0f));\n",
    "    \n",
    "  std::cout << std::endl << \"Range (shape=10, first=0, step=0.1)\" << std::endl;\n",
    "  auto trange = matx::make_tensor<float>({10});\n",
    "  matx::print(trange = matx::range<0>(trange.Shape(), 0.0f, 0.1f));\n",
    "    \n",
    "  std::cout << std::endl << \"Ones (2x3)\" << std::endl;\n",
    "  auto tones = matx::make_tensor<float>({2, 3});\n",
    "  matx::print(tones = matx::ones());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: First Tensor\n",
    "\n",
    "Try defining a new integer tensor of size `{3, 5}` and initilaize its values in increasing values from 0 to 15.\n",
    "\n",
    "print your tensor to ensure the values are as expected.\n",
    "\n",
    "update the 4th element `{1,1}` to `101`.\n",
    "\n",
    "print the 4th element to ensure your update was valid.\n",
    "\n",
    "try other tensor manipulations to test the API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a tensor\n",
    "\n",
    "  // setVals in myTensor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a tensor\n",
    "  // auto myTensor = matx::make_tensor<int>({3,5});\n",
    "\n",
    "  // setVals in myTensor\n",
    "  // myTensor.SetVals({\n",
    "  //                  {1, 2, 3},\n",
    "  //                  {4, 5, 6},\n",
    "  //                  {7, 8, 9},\n",
    "  //                  {10, 11, 12},\n",
    "  //                  {13, 14, 15}\n",
    "  //                  });\n",
    "\n",
    "\n",
    "  // print your new tensor\n",
    "  // matx::print(myTensor);\n",
    "\n",
    "\n",
    "  // update the value at {1,1} to 101\n",
    "  // myTensor(1,1) = 101;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Views\n",
    "MatX provides a powerful set of functions that enable arbitrary views into existing tensors, without incuring additional memory storage or processing cost to reorganize the data. These views provide \"zero copy\" accessors to a tensor that can be used in MatX logic as if it were a real memory-backed tensor.\n",
    "\n",
    "MatX has feature parity to most operations expected in cupy / matlab style environments; a full table of the translation of a given operation to it's MatX equivilant can be found in our full documentation [here](https://nvidia.github.io/MatX/basics/matlabpython.html#conversion-table)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Permute\n",
    "`permute` returns a view of the data with the dimensions swapped to match the order of the initializer list argument. In the exmaple below we swap our two dimenions, so it's equivalent to a matrix transpose. However, `permute` can be used on higher-order tensors with the dimensions swapped in any order.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // setVals in tensor\n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });  \n",
    "\n",
    "  // base tensor\n",
    "  matx::print(t2);\n",
    "\n",
    "  // permute the tensor\n",
    "  auto t2p = matx::permute(t2, {1,0});\n",
    "\n",
    "  // print the permuted tensor to show the transposed data\n",
    "  matx::print(t2p);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice\n",
    "`slice` provides a view of a subset of data in a tensor, allowing that subset to be used and manipulated as a single entity. The `slice` utility function takes the input operator and two initilization lists to define the range of  the provided input operator the slice will container. the ranges are defined wit the start index and end (exclusive) index. \n",
    "\n",
    "in the example below, `t2s` will corespond to the elemnts [`1:2),1:2`] of the larger t2 tensor\n",
    "\n",
    "![2D Slice](../img/dli-slice.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // setVals in tensor\n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });  \n",
    "\n",
    "  //slice example 1: same Rank\n",
    "  auto t2s = matx::slice(t2, {1,1}, {3, 3});\n",
    "\n",
    "  //print the sliced tensor to show the subset of data\n",
    "  matx::print(t2s);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarly, `slice` can be used with a template parameter to define an operator of a different rank (dimensionality) than the input tensor. In the second example, we demonstrate slicing the 0th column from the t2 tensor as shown in the image below.\n",
    "\n",
    "![Column Slice](../img/dli-slice_col.png)\n",
    "\n",
    "MatX also includes several helper defines to make tensor bound definitions easier. To include all values from the beginning on, a special sentinel of `matxEnd` can be used. Similarly, `matxDropDim` is used to indicate this dimension is the one being sliced (i.e. removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // setVals in tensor  \n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });  \n",
    "\n",
    "  //slice example 2: reduce rank requires template parameter\n",
    "  auto t1Col = matx::slice<1>(t2, {0, 1}, {matx::matxEnd, matx::matxDropDim});\n",
    "\n",
    "  //print the sliced tensor to show the subset of data\n",
    "  matx::print(t1Col);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone\n",
    "`clone` provides a utlity funciton to expand a smaller rank tensor to a larger rank by replicating the original data. \n",
    "\n",
    "for example, a 1D Tensor can be cloned to create a 2D tensor.\n",
    "\n",
    "In the clone example below, we will take the t1Col from our previous operation, and clone it to build a 2D [5,4] tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "\n",
    "  // setVals in tensor  \n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });  \n",
    "\n",
    "  //slice example 2: reduce rank requires template parameter\n",
    "  auto t1Col = matx::slice<1>(t2, {0, 1}, {matx::matxEnd, matx::matxDropDim});\n",
    "\n",
    "  //clone the sliced 1D tensor to create a new 2D tensor\n",
    "  auto t2c_cols = matx::clone<2>(t1Col, {5, matx::matxKeepDim});\n",
    "\n",
    "  //print the cloned tensor to show the expanded data\n",
    "  matx::print(t2c_cols);\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data Backing\n",
    "We established earlier that views are not new data, but variable accessors into the original memory-backed tensor. this is a powerful tool when operating on the core data, as we can desctruct a large data block into the set of data we want to operate on. \n",
    "\n",
    "**It is very important to remember that modifying the data in a view modified the original tensor**\n",
    "\n",
    "This means any change to the original tensor, through the view or in any other fashion, will reflect in all views of that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // declare a 2D tensor of size with 4 rows and 5 columns\n",
    "  auto t2 = matx::make_tensor<int>({4,5});\n",
    "  \n",
    "  // setVals in tensor  \n",
    "  t2.SetVals({\n",
    "            {1, 2, 3, 4},\n",
    "            {5, 6, 7, 8},\n",
    "            {9, 10, 11, 12},\n",
    "            {13, 14, 15, 16},\n",
    "            {17, 18, 19, 20}\n",
    "            });  \n",
    "\n",
    "  // slice example 2: reduce rank requires template parameter\n",
    "  auto t1Col = matx::slice<1>(t2, {0, 1}, {matx::matxEnd, matx::matxDropDim});\n",
    "  // clone the sliced 1D tensor to create a new 2D tensor\n",
    "  auto t2c_cols = matx::clone<2>(t1Col, {5, matx::matxKeepDim});\n",
    "\n",
    "\n",
    "  // modify the original tensor\n",
    "  t2(1,0) = 10;\n",
    "  // print our views to show the updated values\n",
    "  matx::print(t2);\n",
    "  matx::print(t1Col);\n",
    "  matx::print(t2c_cols);\n",
    "\n",
    "  // modify the tensor through a view\n",
    "  t1Col(1) = 203;\n",
    "  std::cout << \"------------------- After 203 -------------------\" << std::endl;\n",
    "\n",
    "  // print our views to show the updated values\n",
    "  matx::print(t2);\n",
    "  matx::print(t1Col);\n",
    "  matx::print(t2c_cols);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Views\n",
    "Lets demonstrate your new skills in creating views of a tensor. using the pre-defined `baseTensor2D`, please create the following views:\n",
    "\n",
    "- the complete first row of the `baseTensor`\n",
    "- a 2D square of 4 elements, comprized of the first 2 rows and 2 columns of data\n",
    "- modify the {1,1} element of baseTensor2D through the view corresponding to that data to assign it the value of 87.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  // Make tensor\n",
    "  auto baseTensor2D = matx::make_tensor<int>({3,5});\n",
    "\n",
    "  // Set Values\n",
    "\n",
    "  // slice the first row of baseTensor\n",
    "\n",
    "\n",
    "  //slice the 2D square of the first 4 elements\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// SOLUTION\n",
    "{  \n",
    "  // Make tensor\n",
    "  auto baseTensor2D = matx::make_tensor<int>({3,5});\n",
    "\n",
    "  baseTensor2D.SetVals({\n",
    "                  {1, 2, 3},\n",
    "                  {4, 5, 6},\n",
    "                  {7, 8, 9},\n",
    "                  {10, 11, 12},\n",
    "                  {13, 14, 15}\n",
    "                  });\n",
    "\n",
    "\n",
    "  // slice the first row of baseTensor\n",
    "  auto baseTensor_row0 = matx::slice<1>(baseTensor2D, {0,0}, {matx::matxDropDim, matx::matxEnd});\n",
    "  matx::print(baseTensor_row0);\n",
    "\n",
    "  //slice the 2D square of the first 4 elements\n",
    "  auto baseSquare = matx::slice(baseTensor2D, {0,0}, {3,3});\n",
    "  matx::print(baseSquare);\n",
    "\n",
    "  // baseSquare(1,1) = 87;\n",
    "  matx::print(baseTensor2D);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## MatX Operations\n",
    "Operators in MatX are an abstract type that defines an operation that returns a value at a given index. This concept is intentionally vague, which makes it extremely powerful for representing different concepts. As an example, both a tensor type and the addition operator `+` are MatX operators. In the case of the tensor, it returns the value in memory at that location, but for the addition operator, it returns the sum of values at a given location from both the left and right hand sides.\n",
    "\n",
    "Most operators come in unary types for operating on a single input or a binary type for operating on two inputs. For example, the expression `A + B` uses the binary `AddOp` operator to lazily add two tensors or other operators together. MatX supports most of the standard unary operators a user would expect, and work with both MatX tensor/operator types, as well as scalar values that are compatible with the base type of the operator.\n",
    "\n",
    "below we'll demonstrate both scalar and matrix support for the basic unary operators (`+`, `-`, `x`, `/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  auto A = matx::make_tensor<float>({2, 3});\n",
    "  auto B = matx::make_tensor<float>({2, 3});\n",
    "  auto C = matx::make_tensor<float>({2, 3});\n",
    "  auto D = matx::make_tensor<float>({2, 2});\n",
    "\n",
    "  A.SetVals({ {1.f, 2.f, 3.f},\n",
    "              {4.f, 5.f, 6.f}\n",
    "            });\n",
    "\n",
    "  (B = A).run(exec);\n",
    "\n",
    "  matx::print(A);\n",
    "  matx::print(B);\n",
    "  std::cout << \" val: \" << A(0,0) << std::endl;\n",
    "\n",
    "  // add\n",
    "  matx::print(A + 5.0f); // scalar\n",
    "  matx::print(A + B); // matrix\n",
    "\n",
    "  // subtraction\n",
    "  matx::print(A - 5.0f);\n",
    "  matx::print(A - B);\n",
    "\n",
    "  // multiplication (dot)\n",
    "  matx::print(A * 5.0f);\n",
    "  matx::print(A * B);\n",
    "\n",
    "  // division\n",
    "  matx::print(A / 5.0f);\n",
    "  matx::print(A / B);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Operators\n",
    "Please use the provided A and B tensors to complete the following set of operations:\n",
    "\n",
    "- Multiply `A` by it's scalar weight factor `aScale` to populate tensor `C`\n",
    "- in place subtract `bOffset` from the matrix `B`\n",
    "- Add the `A` and `B` Tensors to poulate tensor `D`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  auto A = matx::make_tensor<float>({2, 3});\n",
    "  auto B = matx::make_tensor<float>({2, 3});\n",
    "  auto C = matx::make_tensor<float>({2, 3});\n",
    "  auto D = matx::make_tensor<float>({2, 2});\n",
    "\n",
    "  A.SetVals({ {1.f, 2.f, 3.f},\n",
    "              {4.f, 5.f, 6.f}\n",
    "            });\n",
    "\n",
    "  (B = A).run(exec);\n",
    "\n",
    "  int aScale = 5;\n",
    "  int bOffset = 2;\n",
    "\n",
    "  // scale A by aScale\n",
    "  // matx::print(/* New Operators here */)\n",
    "\n",
    "  // subtract B by bOffset\n",
    "  // matx::print(/* New Operators here */)\n",
    "\n",
    "  // add A and B Tensors\n",
    "  // matx::print(/* New Operators here */)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catch-up Code for Exercise: Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// cell hidden by default\n",
    "{\n",
    "  auto A = matx::make_tensor<float>({2, 3});\n",
    "  auto B = matx::make_tensor<float>({2, 3});\n",
    "  auto C = matx::make_tensor<float>({2, 3});\n",
    "  auto D = matx::make_tensor<float>({2, 2});\n",
    "\n",
    "  A.SetVals({ {1.f, 2.f, 3.f},\n",
    "              {4.f, 5.f, 6.f}\n",
    "            });\n",
    "\n",
    "  (B = A).run(exec);\n",
    "\n",
    "  int aScale = 5;\n",
    "  int bOffset = 2;\n",
    "\n",
    "  // scale A by aScale\n",
    "  print(A * aScale);\n",
    "\n",
    "  // subtract B by bOffset\n",
    "  print( B - bOffset);\n",
    "\n",
    "  // add A and B Tensors\n",
    "  print(A + B);\n",
    "\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatX Transforms\n",
    "Transforms are operators that take one or more inputs and call a backend library or kernel. Transforms usually changes one or more properties of the input, but that is not always the case. An fft may change the input type or shape, but a sort transform does not. Depending on the context used, a transform may asynchronously allocate temporary memory if the expression requires it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "The `matmul` executor performs the matrix-matrix multiply of $$C = {\\alpha}A * B + {\\beta}C$$ where `A` is of dimensions `MxK`, `B` is `KxN`, and `C` is `MxN`. We first populate the `A` and `B` matrices with random values before the multiply as we did in the example above, then the GEMM is performed. Since the random number generator allocates memory sufficient to randomize the entire tensor, we create a random number generator large enough to generate values for both A or B. This allows us to create a single random number generator, but pull different random values for A and B by simply calling `run` twice. As mentioned above, any rank above 2 is consiered a batching dimension.\n",
    "\n",
    "We use rectangular matrices for `A` and `B`, while `C` will be a square matrix due to the outer dimensions of `A` and `B` matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// matrix multiplication\n",
    "//(D = matx::matmul(A,matx::transpose(B))).run(exec);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFTs\n",
    "MatX provides an interface to do both 1D Fast Fourier Transforms (FFTs) and 2D FFTs. Any tensor above rank 1 will be batched in a 1D FFT, and any tensor above rank 2 will be batched in a 2D FFT. FFTs may either be done in-place or out-of-place by using the same or different variables for the output and inputs. Since the tensors are strongly-typed, the type of FFT (C2C, R2C, etc) is inferred by the tensor type at compile time. Similarly, the input and output size of the executor is deduced by the type of transform, and the input/output tensors must match those sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "// FFT\n",
    "///\\todo commented out because FFT is crashing\n",
    "// (A = matx::random<float>(A.Shape(), matx::NORMAL)).run(exec); // random operator explained later\n",
    "// matx::print(A);\n",
    "\n",
    "// (A = fft(A)).run(exec);\n",
    "// matx::print(A);\n",
    "\n",
    "// (A = matx::ifft(A)).run(exec);\n",
    "// matx::print(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions\n",
    "Reductions are one of the most common operations perfomed on the GPU, which means they've been heavily researched and optimized for highly-parallel processors. Modern NVIDIA GPUs have special instructions for performing reductions to give even larger speedups over naive implementations. All of these details are hidden from the user and MatX automatically chooses the optimized path based on the hardware capabilities. \n",
    "\n",
    "MatX provides a set of optimized primitives to perform reductions on tensors for many common types. Reductions are supported across individual dimensions or on entire tensors, depending on the size of the output tensor. Currently supported reduction functions are `sum`, `min`, `max`,` mean`, `any`, and `all`\n",
    "\n",
    "below is a simple example for calcluate a full reduction of the max and sum of our A data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "\n",
    "  auto A = matx::make_tensor<float>({2, 3});\n",
    "  auto MD0 = matx::make_tensor<float>({});\n",
    "  auto AD0 = matx::make_tensor<float>({});\n",
    "\n",
    "  (A = matx::random<float>(A.Shape(), matx::NORMAL)).run(exec);\n",
    "\n",
    "  // max of data\n",
    "  (MD0 = max(A)).run(exec);\n",
    "  // min of data\n",
    "  (AD0 = sum(A)).run(exec);\n",
    "\n",
    "  exec.sync();\n",
    "\n",
    "  printf(\"A:\\n\");\n",
    "  matx::print(A);\n",
    "  std::cout << \"Max: \" << MD0() << std::endl;\n",
    "  // float test = MD0();\n",
    "  // matx::print(MD0);\n",
    "  // printf(\"Max: %f\\n\", test);\n",
    "  // printf(\"Sum: %f\\n\", AD0());\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Additional Transforms\n",
    "MatX Supports a wide range of transforms, including specializations for specific domains of signal processing. Please review the [MatX documentation](https://nvidia.github.io/MatX/api/index.html) for an exhaustive list of supported operations, but we'll review a few of the most common here.\n",
    "\n",
    "# TODO: Decide if we want to showcase any specific Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "outputs": [],
   "source": [
    "// Do we want to show any additional reducitons here? Talk about batching?\n",
    "// convolution\n",
    "// batched transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatX Generators\n",
    "Generators are a type of operator that can generate values without another tensor or operator as input. For example, windowing functions, such as a Hamming window, can generate values by only taking a length as input. Generators are efficient since they require no memory.\n",
    "\n",
    "Common generators include random number generation, filters, or identity matricies. Below is an example of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  auto A = matx::make_tensor<float>({2, 3});\n",
    "  auto H = matx::make_tensor<float>({10});\n",
    "\n",
    "  // random\n",
    "  (A = 0).run(exec);\n",
    "  (A = matx::random<float>(A.Shape(), matx::NORMAL)).run(exec);\n",
    "  matx::print(A);\n",
    "\n",
    "  // eye\n",
    "  (A = matx::eye(A.Shape())).run(exec);\n",
    "  matx::print(A);\n",
    "\n",
    "  // hamming\n",
    "  (H = matx::hamming<0>(H.Shape())).run(exec);\n",
    "  matx::print(H);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Transforms and generators:\n",
    "\n",
    "For this example we will generate random data to verify the distribution of our generator functions. Please implement the following:\n",
    "\n",
    "- generate 10 1D data arrays of 1000 elements\n",
    "- perform a 1D FFT on the entire data set\n",
    "- find the max bin of each fft'd data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c++"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "\n",
    "  //input data storage\n",
    "  auto input = matx::make_tensor<float>({10,1000});\n",
    "  auto maxVal = matx::make_tensor<matx::index_t>({10});\n",
    "  auto maxIdx = matx::make_tensor<size_t>({10});\n",
    "\n",
    "  // generate random data\n",
    "  // (input = matx::random<float(input.Shape())).run(exec);\n",
    "\n",
    "  // perform FFT\n",
    "  // auto input = matx::fft(input, matx::NORMAL);\n",
    "\n",
    "  // finx max bins and values\n",
    "  // (mtie(maxVal, maxIdx) = argmax(input, {0})).run(exec);\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++",
   "name": "cling-cpp17"
  },
  "language_info": {
   "codemirror_mode": "c++",
   "file_extension": ".c++",
   "mimetype": "text/x-c++src",
   "name": "C++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
