{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: This notebook is configured for bash execution, not C++, so you won't be able to run the C++ code examples shown*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling in MatX\n",
    "Improving performance is at the heart of MatX's value, so it must facilitate any easy to implement and powerful capability for benchmarking and analysing code both at deployment and during development.\n",
    "\n",
    "The NVIDIA software ecosystem provides a powerful profiling suite of tools through [Nsight Systems]() and [Nsight Compute]() that allows developers to gain great insight into the performance of their code and utilization of their hardware. MatX leverages this powerful ecosystem through the [NVTX toolkit]() which allows developers to annote their code for use with the Nsight suite of tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor Timers\n",
    "Before we get into the meat of the profiling section, let's talk about a profiling approach you used earlier. The simplest, most light-weight (but less powerful) way to profile a block of MatX code is to leverage the built-in timer in the executor.\n",
    "\n",
    "These methods don't integrate with the Nsight toolset, but can be useful for quick and dirty analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "exec.start_timer();\n",
    "(C = A * fft(B)).run(exec);\n",
    "exec.stop_timer();\n",
    "std::cout << \"Execution time: \" << exec.get_time_ms() << \" ms\" << std::endl;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatX Profiling Tools\n",
    "MatX provides an NVTX API to enable native compile-in profiling capabilities. The MatX NVTX API enable a user to \n",
    "easily profile all MatX calls using built-in NVTX ranges, while also providing a convenient API for the user to insert \n",
    "custom ranges in their own code. This API provides many convenience features such as:\n",
    "\n",
    "- A convenient compile-in/compile-out MACRO based API \n",
    "- verbosity levels allowing varying levels of profiling detail\n",
    "- Built-in color rotation\n",
    "- Automatic scope management and range naming \n",
    "- Overloaded API for manual range specification\n",
    "\n",
    "MatX Implements it's NVTX API as a set of macros, which allows users to easily compile NVTX functionality into, or out of your code. This completely removes any runtime penality that may be caused by NVTX in the most latency sensitive deployments.\n",
    "\n",
    "To enable the NVTX Profiling API, simply compile with the ``MATX_NVTX_FLAGS=ON`` enabled in the cmake command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Ranges\n",
    "User defined NVTX ranges require the user to provide a name and unique ID for each range. The name will appear in the NVTX range of your nsight profiles, while the unique ID is only used interally to track your ranges during deletion. Because of this, the unique ID **must** be unique for any ranges that overlap, otherwise you may delete the incorrect range during tear-down.\n",
    "\n",
    "Below is an example of a user-defined NVTX range:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "source": [
    "```c++\n",
    "using dtype = double;\n",
    "index_t input_size = 10;\n",
    "// index_t inputIsze  = 10000000; // increase size to measure performance\n",
    "\n",
    "MATX_NVTX_START_RANGE(\"Black-Scholes Memory Allocation\", 0)\n",
    "// declare input data\n",
    "auto K = matx::make_tensor<dtype>({input_size});\n",
    "auto S = matx::make_tensor<dtype>({input_size});\n",
    "auto V = matx::make_tensor<dtype>({input_size});\n",
    "auto r = matx::make_tensor<dtype>({input_size});\n",
    "auto T = matx::make_tensor<dtype>({input_size});\n",
    "auto output = matx::make_tensor<dtype>({input_size});  \n",
    "auto referenceOutput = matx::make_tensor<dtype>({input_size});  \n",
    "MATX_NVTX_END_RANGE(0)\n",
    "\n",
    "\n",
    "MATX_NVTX_START_RANGE(\"Black-Scholes Op Creation\", 1)\n",
    "// create ops\n",
    "auto VsqrtT = V * sqrt(T);\n",
    "auto d1     = (log(S / K) + (r + 0.5 * V * V) * T) / VsqrtT ;\n",
    "auto d2     = d1 - VsqrtT;\n",
    "auto cdf_d1 = normcdf(d1);\n",
    "auto cdf_d2 = normcdf(d2);\n",
    "auto expRT  = exp(-1 * r * T); \n",
    "MATX_NVTX_END_RANGE(1)\n",
    "\n",
    "MATX_NVTX_START_RANGE(\"Black-Scholes Execution\", 2)\n",
    "// execute ops\n",
    "(output = S * cdf_d1 - K * expRT * cdf_d2).run(exec);\n",
    "MATX_NVTX_END_RANGE(2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Ranges\n",
    "Alternative versions of the timing macros are provided to auomate handling the NatX NVTX ranges. The `MATX_NVTX_START_RANGE` has an overload which allows the its use without providing a unique ID. Instead the macro returns an ID, which can be stored in an int variable and later passed to the end range call. when NVTX ranges are compiled out, the Macros simply return 0, and no action is taken on the end call.\n",
    "\n",
    "Below is an example using the automatic enumeration feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "source": [
    "```c++\n",
    "int bc_range = MATX_NVTX_START_RANGE(\"Black-Scholes Execution\");\n",
    "(output = S * cdf_d1 - K * expRT * cdf_d2).run(exec);\n",
    "MATX_NVTX_END_RANGE(bc_range);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope Based Ranges\n",
    "A final version of the API, `MATX_NVTX_START` is provided that matches the life of the NVTX range to the life of the scope in which it is defined. This automatically enumates a unique ID, and does not need to be explicitly destroyed by the user. \n",
    "\n",
    "Similarly it will also inherit the name of the functions it is called from, and do not require a name. This is especially useful for automating ranges for entire functions.\n",
    "\n",
    "An example of this API is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "source": [
    "```c++\n",
    "void myFunction\n",
    "{\n",
    "  MATX_NVTX_START(\"\");\n",
    "  \n",
    "  (output = S * cdf_d1 - K * expRT * cdf_d2).run(exec);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Profile Level \n",
    "The MatX NVTX API supports logging levels, allowing you to fine-tune the levels of NVTX ranges that are captured at a given time. the logging level is checked at runtime, so can be dynamically changed throughout program execution.\n",
    "A utility macro  `MATX_NVTX_SET_LOG_LEVEL(LOG_LEVEL)`.\n",
    "\n",
    "All Events default to the log level `MATX_NVTX_LOG_USER`, and the default verbosity is `MATX_NVTX_LOG_API`. \n",
    "\n",
    "\n",
    "There are 5 increasing levels of verbosity:\n",
    "\n",
    "```c++\n",
    "MATX_NVTX_LOG_NONE\n",
    "MATX_NVTX_LOG_USER\n",
    "MATX_NVTX_LOG_API\n",
    "MATX_NVTX_LOG_INTERNAL\n",
    "MATX_NVTX_LOG_ALL\n",
    "``` \n",
    "\n",
    "`MATX_NVTX_LOG_NONE` ensures that no Ranges are recorded.\n",
    "`MATX_NVTX_LOG_ALL` ensures all NVTX Ranges are recorded.\n",
    "\n",
    "Any intermediate level ensures that level and all levesl avove it are recoded. For exmaple, if `MATX_NVTX_LOG_API`\n",
    "is enabled, then all events of type `MATX_NVTX_LOG_USER` **AND** `MATX_NVTX_LOG_API` will be recoded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Profiling Examples\n",
    "In this section we're going to use some pre-built applications to demonstrate how to generate an Nsight Systems profile and do some basic, high-level analysis using the Nsight Systems CLI.\n",
    "\n",
    "To take advantage of the full Nsight Systems profiler, you must example the profile report with the GUI, which isn't installed in this lab. We'll show screenshots of the output you'll see, but to interact with the reports yourself, head to https://developer.nvidia.com/nsight-systems to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Fusion Application\n",
    "The first application we'll be profiling is one you've already seen before. In `samples/kernel_fusion.cu`, we've implemented a simple application that demonstrates the same concepts learned in the earlier section about operator fusion.\n",
    "\n",
    "Specifically, we implement 2 ranges, looping over each 10 times to get an accurate timing analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "// first individual, independent kernels\n",
    "int unfused_range = MATX_NVTX_START_RANGE(\"Unfused Kernels\");\n",
    "(result = cos(C)).run(exec);\n",
    "(result = result / D).run(exec);\n",
    "(result = result * B).run(exec);\n",
    "MATX_NVTX_END_RANGE(unfused_range);\n",
    "\n",
    "// now, as a fused operation\n",
    "int fused_range = MATX_NVTX_START_RANGE(\"Fused Operation\");\n",
    "(A = B * cos(C)/D).run(exec);\n",
    "MATX_NVTX_END_RANGE(fused_range);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate an Nsight Systems profile report on the application, which is saved as `samples/kernel_fusion_report.nsys-rep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsys profile -o ./samples/kernel_fusion_report.nsys-rep ./samples/kernel_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `.nsys-rep` file is what is used by Nsight Systems for profiling and is what you would load into the Nsight Systems GUI. To see some high-level statistics, let's use the CLI in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsys stats ./samples/kernel_fusion_report.nsys-rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the top section, `** NVTX Range Summary`, take note of the `MatX:Unfused Kernels` and `MatX:Fused Operation` ranges on the right. You should see something like:\n",
    "```\n",
    " ** NVTX Range Summary (nvtxsum):\n",
    "\n",
    "Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)  Min (ns)   Max (ns)   StdDev (ns)   Style                                            Range                                        \n",
    "--------  ---------------  ---------  -----------  --------  --------  ----------  -----------  --------  -------------------------------------------------------------------------------------\n",
    "...\n",
    "     1.0          338,264         10     33,826.4  31,930.0    30,941      44,218      4,231.5  StartEnd  MatX:Unfused Kernels\n",
    "     0.4          145,858         10     14,585.8  13,614.0    13,019      21,775      2,730.8  StartEnd  MatX:Fused Operation\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the output you'd see in Nsight Systems GUI. This plot shows a high-level view of all 10 iterations we just ran:\n",
    "\n",
    "![Fusion High Level](img/kernel-fusion-highlevel.png)\n",
    "\n",
    "We can zoom down to a single iteration to compare the two ranges:\n",
    "\n",
    "![Fusion High Level](img/kernel-fusion-lowlevel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Radar Application\n",
    "To demonstrate the power of the NVTX ranges, we'll demonstrate using a more complex example: the [Simple Radar Pipeline](https://github.com/NVIDIA/MatX/blob/main/examples/simple_radar_pipeline.cu) that comes with the MatX example codes. This pipeline showcases both the powerful accleration MatX provides, as well as the granular insight we gain into our performance through the MatX NVTX API.\n",
    "\n",
    "You can view the file here at `./samples/simple_radar_pipeline.cu` and `./samples/simple_radar_pipeline.h`.\n",
    "\n",
    "The pipeline is made up of 4 stages:\n",
    "1. Pulse Compression - An FFT, a dot matrix multiply, and an inverse FFT\n",
    "2. Three Pulse Canceller - A 1D convolution\n",
    "3. Doppler Processing - A dot matrix multiply with a Hamming window and an FFT\n",
    "4. CFAR Detection - An element-wise magnitude-squared, a 2D convolution, a dot matrix divide\n",
    "\n",
    "Which operations do you think will take the longest? The fastest?\n",
    "\n",
    "Run the cell below to generate a profile report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsys profile -o ./samples/simple_radar_pipeline_report.nsys-rep ./samples/simple_radar_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below for a high-level view of the profile output (this one is a lot more complicated!):\n",
    "\n",
    "![Radar High-Level](img/radar-highlevel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look, zoomed into a single pass-through of all 4 stages of the pipeline:\n",
    "\n",
    "![Radar Pipeline](img/radar-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And zoomed in even further to just look at the Pulse Compression stage:\n",
    "\n",
    "![Radar Pulse Compression](img/radar-pulsecompression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the cell below to see the CLI output for some high-level statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsys stats ./samples/simple_radar_pipeline_report.nsys-rep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
